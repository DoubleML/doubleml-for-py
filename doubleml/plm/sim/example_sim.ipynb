{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01469cb2",
   "metadata": {},
   "source": [
    "### Double Machine Learning for Static Panel Models with Fixed Effects\n",
    "\n",
    "Extending the partially linear model to panel data by introducing fixed effects $\\alpha_i$ to give the partially linear panel regression (PLPR) model.\n",
    "\n",
    "Partialled-out PLPR (PO-PLPR) model:\n",
    "\n",
    "\\begin{align*}\n",
    "    Y_{it} &= \\theta_0 D_{it} + g_0(X_{it}) + \\alpha_i + U_{it} \\\\\n",
    "    D_{it} &= m_0(X_{it}) + \\gamma_i + V_{it}\n",
    "\\end{align*}\n",
    "\n",
    "- $Y_{it}$ outcome, $D_{it}$ treatment, $X_{it}$ covariates, $\\theta_0$ causal treatment effect\n",
    "- $g_0$ and $m_0$ nuisance functions\n",
    "- $\\alpha_i$, $\\gamma_i$ unobserved individual heterogeneity, correlated with covariates\n",
    "- $U_{it}$, $V_{it}$ error terms\n",
    "\n",
    "Further note $E[U_{it} \\mid D_{it}, X_{it}, \\alpha_i] = 0$, but $E[\\alpha_i \\mid D_{it}, X_{it}] \\neq 0$, and $E[V_{it} \\mid X_{it}, \\gamma_i]=0$\n",
    "\n",
    "#### 1 Correlated Random Effect Approach\n",
    "\n",
    "##### 1.1. General case:\n",
    "\n",
    "- Learning $g_0$ from $\\{ Y_{it}, X_{it}, \\bar{X}_i : t=1,\\dots, T \\}_{i=1}^N$\n",
    "- First learning $\\tilde{m}_0({\\cdot})$ from $\\{ D_{it}, X_{it}, \\bar{X}_i : t=1,\\dots, T \\}_{i=1}^N$ with prediction $\\hat{m}_{0it} = \\tilde{m}_0 (X_{it}, \\bar{X}_i) $\n",
    "    - Calculate $\\hat{\\bar{m}}_i = T^{-1} \\sum_{t=1}^T \\hat{m}_{0it} $\n",
    "    - Calculate final nuisance part as $ \\hat{m}^*_0 (X_{it}, \\bar{X}_i, \\bar{D}_i) = \\hat{m}_{0it} + \\bar{D}_i - \\hat{\\bar{m}}_i $ \n",
    "\n",
    "##### 1.2. Normal assumption:\n",
    "\n",
    "(conditional distribution $ D_{i1}, \\dots, D_{iT} \\mid X_{i1}, \\dots X_{iT} $ is multivariate normal)\n",
    "- Learn $m^*_{0}$ from $\\{ D_{it}, X_{it}, \\bar{X}_i, \\bar{D}_i: t=1,\\dots, T \\}_{i=1}^N$\n",
    "\n",
    "#### 2. Transformation Approaches\n",
    "\n",
    "##### 2.1. First Difference (FD) Transformation - Exact\n",
    "\n",
    "Consider FD transformation $Q(Y_{it})= Y_{it} - Y_{it-1} $, under Assumptions 3.1-3.5, transformed nuisance function can be learnt as\n",
    "\n",
    "- $ \\Delta g_0 (X_{it-1}, X_{it}) $ from $ \\{ Y_{it}-Y_{it-1}, X_{it-1}, X_{it} : t=2, \\dots , T \\}_{i=1}^N $\n",
    "- $ \\Delta m_0 (X_{it-1}, X_{it}) $ from $ \\{ D_{it}-D_{it-1}, X_{it-1}, X_{it} : t=2, \\dots , T \\}_{i=1}^N $\n",
    "\n",
    "##### 2.2. Within Group (WG) Transformation - Approximate\n",
    "\n",
    "For WG transformation $Q(X_{it})= X_{it} - \\bar{X}_{i} $, where $ \\bar{X}_{i} = T^{-1} \\sum_{t=1}^T X_{it} $. Approximate model\n",
    "\\begin{align*}\n",
    "    Q(Y_{it}) &\\approx \\theta_0 Q(D_{it}) + g_0 (Q(X_{it})) + Q(U_{it}) \\\\\n",
    "    Q(D_{it}) &\\approx m_0 (Q(X_{it})) + Q(V_{it})\n",
    "\\end{align*}\n",
    "\n",
    "- $g_0$ can be learnt from transformed data $ \\{ Q(Y_{it}), Q(X_{it}) : t=1,\\dots,T \\}_{i=1}^N $\n",
    "- $m_0$ can be learnt from transformed data $ \\{ Q(D_{it}), Q(X_{it}) : t=1,\\dots,T \\}_{i=1}^N $\n",
    "\n",
    "#### Implementation\n",
    "\n",
    "- Using block-k-fold cross-fitting, where the entire time series of the sampled unit is allocated to one fold to allow for possible serial correlation\n",
    "within each unit as is common with panel data\n",
    "\n",
    "- Cluster robust standard error\n",
    "\n",
    "$\\Rightarrow$ using id variable as cluster for DML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dfa56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from doubleml.data.base_data import DoubleMLData \n",
    "from doubleml.data.panel_data import DoubleMLPanelData\n",
    "from doubleml.plm.plpr import DoubleMLPLPR\n",
    "from sklearn.linear_model import LassoCV, LinearRegression\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from doubleml.plm.utils._plpr_util import cre_fct, fd_fct, wd_fct, extend_data\n",
    "from doubleml.plm.datasets.dgp_static_panel_CP2025 import make_static_panel_CP2025\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c061cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6719371174913912),\n",
       " np.float64(0.6090488219157397),\n",
       " np.float64(0.7348254130670426))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "data = make_static_panel_CP2025(dgp_type='dgp1')\n",
    "\n",
    "x_cols = [col for col in data.columns if \"x\" in col]\n",
    "\n",
    "X = sm.add_constant(data[['d'] + x_cols])\n",
    "y = data['y']\n",
    "clusters = data['id']\n",
    "\n",
    "ols_model = sm.OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': clusters})\n",
    "ols_model.params['d'], ols_model.conf_int().loc['d'][0], ols_model.conf_int().loc['d'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       coef   std err          t          P>|t|     2.5 %    97.5 %\n",
      "d  0.456003  0.020668  22.063024  7.163019e-108  0.415494  0.496512\n"
     ]
    }
   ],
   "source": [
    "# cre general\n",
    "\n",
    "# np.random.seed(1)\n",
    "data = make_static_panel_CP2025(dgp_type='dgp1')\n",
    "cre_data = cre_fct(data)\n",
    "\n",
    "x_cols = [col for col in cre_data.columns if \"x\" in col]\n",
    "\n",
    "learner = LassoCV()\n",
    "ml_l = clone(learner)\n",
    "ml_m = clone(learner)\n",
    "\n",
    "obj_panel = DoubleMLPanelData(cre_data,\n",
    "                              y_col='y',\n",
    "                              d_cols='d',\n",
    "                              t_col='time',\n",
    "                              id_col='id',\n",
    "                              x_cols=x_cols,\n",
    "                              static_panel=True)\n",
    "\n",
    "dml_panel_plpr = DoubleMLPLPR(obj_panel, ml_l=ml_l, ml_m=ml_m,\n",
    "                              approach='cre_general', n_folds=5\n",
    "                              )\n",
    "dml_panel_plpr.fit()\n",
    "print(dml_panel_plpr.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44387af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       coef   std err          t          P>|t|     2.5 %    97.5 %\n",
      "d  0.515035  0.020056  25.679326  1.989663e-145  0.475725  0.554345\n"
     ]
    }
   ],
   "source": [
    "data = make_static_panel_CP2025(dgp_type='dgp1')\n",
    "\n",
    "x_cols = [col for col in data.columns if \"x\" in col]\n",
    "\n",
    "learner = LassoCV()\n",
    "ml_l = clone(learner)\n",
    "ml_m = clone(learner)\n",
    "\n",
    "obj_panel = DoubleMLPanelData(data,\n",
    "                              y_col='y',\n",
    "                              d_cols='d',\n",
    "                              t_col='time',\n",
    "                              id_col='id',\n",
    "                              x_cols=x_cols,\n",
    "                              static_panel=True)\n",
    "\n",
    "dml_panel_plpr = DoubleMLPLPR(obj_panel, ml_l=ml_l, ml_m=ml_m,\n",
    "                              approach='cre_general', n_folds=5\n",
    "                              )\n",
    "dml_panel_plpr.fit()\n",
    "print(dml_panel_plpr.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8592f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(array([   0,    1,    2, ..., 2497, 2498, 2499], shape=(2000,)),\n",
       "   array([  60,   61,   62,   63,   64,   65,   66,   67,   68,   69,  100,\n",
       "           101,  102,  103,  104,  105,  106,  107,  108,  109,  110,  111,\n",
       "           112,  113,  114,  115,  116,  117,  118,  119,  160,  161,  162,\n",
       "           163,  164,  165,  166,  167,  168,  169,  180,  181,  182,  183,\n",
       "           184,  185,  186,  187,  188,  189,  270,  271,  272,  273,  274,\n",
       "           275,  276,  277,  278,  279,  280,  281,  282,  283,  284,  285,\n",
       "           286,  287,  288,  289,  310,  311,  312,  313,  314,  315,  316,\n",
       "           317,  318,  319,  360,  361,  362,  363,  364,  365,  366,  367,\n",
       "           368,  369,  410,  411,  412,  413,  414,  415,  416,  417,  418,\n",
       "           419,  630,  631,  632,  633,  634,  635,  636,  637,  638,  639,\n",
       "           720,  721,  722,  723,  724,  725,  726,  727,  728,  729,  770,\n",
       "           771,  772,  773,  774,  775,  776,  777,  778,  779,  810,  811,\n",
       "           812,  813,  814,  815,  816,  817,  818,  819,  870,  871,  872,\n",
       "           873,  874,  875,  876,  877,  878,  879,  880,  881,  882,  883,\n",
       "           884,  885,  886,  887,  888,  889,  990,  991,  992,  993,  994,\n",
       "           995,  996,  997,  998,  999, 1050, 1051, 1052, 1053, 1054, 1055,\n",
       "          1056, 1057, 1058, 1059, 1160, 1161, 1162, 1163, 1164, 1165, 1166,\n",
       "          1167, 1168, 1169, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237,\n",
       "          1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248,\n",
       "          1249, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269,\n",
       "          1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1390,\n",
       "          1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1540, 1541,\n",
       "          1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1570, 1571, 1572,\n",
       "          1573, 1574, 1575, 1576, 1577, 1578, 1579, 1660, 1661, 1662, 1663,\n",
       "          1664, 1665, 1666, 1667, 1668, 1669, 1680, 1681, 1682, 1683, 1684,\n",
       "          1685, 1686, 1687, 1688, 1689, 1760, 1761, 1762, 1763, 1764, 1765,\n",
       "          1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776,\n",
       "          1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787,\n",
       "          1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798,\n",
       "          1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809,\n",
       "          1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880,\n",
       "          1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1910, 1911,\n",
       "          1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1970, 1971, 1972,\n",
       "          1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983,\n",
       "          1984, 1985, 1986, 1987, 1988, 1989, 2000, 2001, 2002, 2003, 2004,\n",
       "          2005, 2006, 2007, 2008, 2009, 2040, 2041, 2042, 2043, 2044, 2045,\n",
       "          2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056,\n",
       "          2057, 2058, 2059, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077,\n",
       "          2078, 2079, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108,\n",
       "          2109, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219,\n",
       "          2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2260,\n",
       "          2261, 2262, 2263, 2264, 2265, 2266, 2267, 2268, 2269, 2300, 2301,\n",
       "          2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312,\n",
       "          2313, 2314, 2315, 2316, 2317, 2318, 2319, 2340, 2341, 2342, 2343,\n",
       "          2344, 2345, 2346, 2347, 2348, 2349, 2370, 2371, 2372, 2373, 2374,\n",
       "          2375, 2376, 2377, 2378, 2379])),\n",
       "  (array([   0,    1,    2, ..., 2487, 2488, 2489], shape=(2000,)),\n",
       "   array([  20,   21,   22,   23,   24,   25,   26,   27,   28,   29,   50,\n",
       "            51,   52,   53,   54,   55,   56,   57,   58,   59,   70,   71,\n",
       "            72,   73,   74,   75,   76,   77,   78,   79,  120,  121,  122,\n",
       "           123,  124,  125,  126,  127,  128,  129,  150,  151,  152,  153,\n",
       "           154,  155,  156,  157,  158,  159,  170,  171,  172,  173,  174,\n",
       "           175,  176,  177,  178,  179,  300,  301,  302,  303,  304,  305,\n",
       "           306,  307,  308,  309,  320,  321,  322,  323,  324,  325,  326,\n",
       "           327,  328,  329,  540,  541,  542,  543,  544,  545,  546,  547,\n",
       "           548,  549,  650,  651,  652,  653,  654,  655,  656,  657,  658,\n",
       "           659,  660,  661,  662,  663,  664,  665,  666,  667,  668,  669,\n",
       "           710,  711,  712,  713,  714,  715,  716,  717,  718,  719,  730,\n",
       "           731,  732,  733,  734,  735,  736,  737,  738,  739,  840,  841,\n",
       "           842,  843,  844,  845,  846,  847,  848,  849,  960,  961,  962,\n",
       "           963,  964,  965,  966,  967,  968,  969,  970,  971,  972,  973,\n",
       "           974,  975,  976,  977,  978,  979, 1000, 1001, 1002, 1003, 1004,\n",
       "          1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015,\n",
       "          1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026,\n",
       "          1027, 1028, 1029, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067,\n",
       "          1068, 1069, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098,\n",
       "          1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109,\n",
       "          1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1180,\n",
       "          1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1250, 1251,\n",
       "          1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1270, 1271, 1272,\n",
       "          1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283,\n",
       "          1284, 1285, 1286, 1287, 1288, 1289, 1320, 1321, 1322, 1323, 1324,\n",
       "          1325, 1326, 1327, 1328, 1329, 1340, 1341, 1342, 1343, 1344, 1345,\n",
       "          1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356,\n",
       "          1357, 1358, 1359, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417,\n",
       "          1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428,\n",
       "          1429, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479,\n",
       "          1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1610,\n",
       "          1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1650, 1651,\n",
       "          1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1700, 1701, 1702,\n",
       "          1703, 1704, 1705, 1706, 1707, 1708, 1709, 1750, 1751, 1752, 1753,\n",
       "          1754, 1755, 1756, 1757, 1758, 1759, 1920, 1921, 1922, 1923, 1924,\n",
       "          1925, 1926, 1927, 1928, 1929, 2080, 2081, 2082, 2083, 2084, 2085,\n",
       "          2086, 2087, 2088, 2089, 2140, 2141, 2142, 2143, 2144, 2145, 2146,\n",
       "          2147, 2148, 2149, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177,\n",
       "          2178, 2179, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248,\n",
       "          2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259,\n",
       "          2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330,\n",
       "          2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2350, 2351,\n",
       "          2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362,\n",
       "          2363, 2364, 2365, 2366, 2367, 2368, 2369, 2390, 2391, 2392, 2393,\n",
       "          2394, 2395, 2396, 2397, 2398, 2399, 2490, 2491, 2492, 2493, 2494,\n",
       "          2495, 2496, 2497, 2498, 2499])),\n",
       "  (array([  20,   21,   22, ..., 2497, 2498, 2499], shape=(2000,)),\n",
       "   array([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
       "            11,   12,   13,   14,   15,   16,   17,   18,   19,  190,  191,\n",
       "           192,  193,  194,  195,  196,  197,  198,  199,  200,  201,  202,\n",
       "           203,  204,  205,  206,  207,  208,  209,  210,  211,  212,  213,\n",
       "           214,  215,  216,  217,  218,  219,  220,  221,  222,  223,  224,\n",
       "           225,  226,  227,  228,  229,  290,  291,  292,  293,  294,  295,\n",
       "           296,  297,  298,  299,  340,  341,  342,  343,  344,  345,  346,\n",
       "           347,  348,  349,  350,  351,  352,  353,  354,  355,  356,  357,\n",
       "           358,  359,  440,  441,  442,  443,  444,  445,  446,  447,  448,\n",
       "           449,  460,  461,  462,  463,  464,  465,  466,  467,  468,  469,\n",
       "           470,  471,  472,  473,  474,  475,  476,  477,  478,  479,  490,\n",
       "           491,  492,  493,  494,  495,  496,  497,  498,  499,  530,  531,\n",
       "           532,  533,  534,  535,  536,  537,  538,  539,  560,  561,  562,\n",
       "           563,  564,  565,  566,  567,  568,  569,  580,  581,  582,  583,\n",
       "           584,  585,  586,  587,  588,  589,  600,  601,  602,  603,  604,\n",
       "           605,  606,  607,  608,  609,  610,  611,  612,  613,  614,  615,\n",
       "           616,  617,  618,  619,  690,  691,  692,  693,  694,  695,  696,\n",
       "           697,  698,  699,  750,  751,  752,  753,  754,  755,  756,  757,\n",
       "           758,  759,  780,  781,  782,  783,  784,  785,  786,  787,  788,\n",
       "           789,  800,  801,  802,  803,  804,  805,  806,  807,  808,  809,\n",
       "           900,  901,  902,  903,  904,  905,  906,  907,  908,  909,  920,\n",
       "           921,  922,  923,  924,  925,  926,  927,  928,  929,  950,  951,\n",
       "           952,  953,  954,  955,  956,  957,  958,  959,  980,  981,  982,\n",
       "           983,  984,  985,  986,  987,  988,  989, 1110, 1111, 1112, 1113,\n",
       "          1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124,\n",
       "          1125, 1126, 1127, 1128, 1129, 1150, 1151, 1152, 1153, 1154, 1155,\n",
       "          1156, 1157, 1158, 1159, 1190, 1191, 1192, 1193, 1194, 1195, 1196,\n",
       "          1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207,\n",
       "          1208, 1209, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458,\n",
       "          1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469,\n",
       "          1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1580,\n",
       "          1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1730, 1731,\n",
       "          1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742,\n",
       "          1743, 1744, 1745, 1746, 1747, 1748, 1749, 1820, 1821, 1822, 1823,\n",
       "          1824, 1825, 1826, 1827, 1828, 1829, 1840, 1841, 1842, 1843, 1844,\n",
       "          1845, 1846, 1847, 1848, 1849, 1890, 1891, 1892, 1893, 1894, 1895,\n",
       "          1896, 1897, 1898, 1899, 1930, 1931, 1932, 1933, 1934, 1935, 1936,\n",
       "          1937, 1938, 1939, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957,\n",
       "          1958, 1959, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018,\n",
       "          2019, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039,\n",
       "          2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2180,\n",
       "          2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2280, 2281,\n",
       "          2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2400, 2401, 2402,\n",
       "          2403, 2404, 2405, 2406, 2407, 2408, 2409, 2440, 2441, 2442, 2443,\n",
       "          2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454,\n",
       "          2455, 2456, 2457, 2458, 2459])),\n",
       "  (array([   0,    1,    2, ..., 2497, 2498, 2499], shape=(2000,)),\n",
       "   array([  40,   41,   42,   43,   44,   45,   46,   47,   48,   49,   80,\n",
       "            81,   82,   83,   84,   85,   86,   87,   88,   89,   90,   91,\n",
       "            92,   93,   94,   95,   96,   97,   98,   99,  230,  231,  232,\n",
       "           233,  234,  235,  236,  237,  238,  239,  240,  241,  242,  243,\n",
       "           244,  245,  246,  247,  248,  249,  260,  261,  262,  263,  264,\n",
       "           265,  266,  267,  268,  269,  370,  371,  372,  373,  374,  375,\n",
       "           376,  377,  378,  379,  380,  381,  382,  383,  384,  385,  386,\n",
       "           387,  388,  389,  400,  401,  402,  403,  404,  405,  406,  407,\n",
       "           408,  409,  480,  481,  482,  483,  484,  485,  486,  487,  488,\n",
       "           489,  680,  681,  682,  683,  684,  685,  686,  687,  688,  689,\n",
       "           700,  701,  702,  703,  704,  705,  706,  707,  708,  709,  740,\n",
       "           741,  742,  743,  744,  745,  746,  747,  748,  749,  760,  761,\n",
       "           762,  763,  764,  765,  766,  767,  768,  769,  820,  821,  822,\n",
       "           823,  824,  825,  826,  827,  828,  829,  830,  831,  832,  833,\n",
       "           834,  835,  836,  837,  838,  839,  850,  851,  852,  853,  854,\n",
       "           855,  856,  857,  858,  859,  930,  931,  932,  933,  934,  935,\n",
       "           936,  937,  938,  939, 1030, 1031, 1032, 1033, 1034, 1035, 1036,\n",
       "          1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047,\n",
       "          1048, 1049, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078,\n",
       "          1079, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149,\n",
       "          1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1210,\n",
       "          1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1290, 1291,\n",
       "          1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302,\n",
       "          1303, 1304, 1305, 1306, 1307, 1308, 1309, 1360, 1361, 1362, 1363,\n",
       "          1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374,\n",
       "          1375, 1376, 1377, 1378, 1379, 1400, 1401, 1402, 1403, 1404, 1405,\n",
       "          1406, 1407, 1408, 1409, 1440, 1441, 1442, 1443, 1444, 1445, 1446,\n",
       "          1447, 1448, 1449, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507,\n",
       "          1508, 1509, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538,\n",
       "          1539, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559,\n",
       "          1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1600,\n",
       "          1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1620, 1621,\n",
       "          1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632,\n",
       "          1633, 1634, 1635, 1636, 1637, 1638, 1639, 1690, 1691, 1692, 1693,\n",
       "          1694, 1695, 1696, 1697, 1698, 1699, 1710, 1711, 1712, 1713, 1714,\n",
       "          1715, 1716, 1717, 1718, 1719, 1850, 1851, 1852, 1853, 1854, 1855,\n",
       "          1856, 1857, 1858, 1859, 1990, 1991, 1992, 1993, 1994, 1995, 1996,\n",
       "          1997, 1998, 1999, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097,\n",
       "          2098, 2099, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118,\n",
       "          2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129,\n",
       "          2160, 2161, 2162, 2163, 2164, 2165, 2166, 2167, 2168, 2169, 2200,\n",
       "          2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2380, 2381,\n",
       "          2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2410, 2411, 2412,\n",
       "          2413, 2414, 2415, 2416, 2417, 2418, 2419, 2470, 2471, 2472, 2473,\n",
       "          2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484,\n",
       "          2485, 2486, 2487, 2488, 2489])),\n",
       "  (array([   0,    1,    2, ..., 2497, 2498, 2499], shape=(2000,)),\n",
       "   array([  30,   31,   32,   33,   34,   35,   36,   37,   38,   39,  130,\n",
       "           131,  132,  133,  134,  135,  136,  137,  138,  139,  140,  141,\n",
       "           142,  143,  144,  145,  146,  147,  148,  149,  250,  251,  252,\n",
       "           253,  254,  255,  256,  257,  258,  259,  330,  331,  332,  333,\n",
       "           334,  335,  336,  337,  338,  339,  390,  391,  392,  393,  394,\n",
       "           395,  396,  397,  398,  399,  420,  421,  422,  423,  424,  425,\n",
       "           426,  427,  428,  429,  430,  431,  432,  433,  434,  435,  436,\n",
       "           437,  438,  439,  450,  451,  452,  453,  454,  455,  456,  457,\n",
       "           458,  459,  500,  501,  502,  503,  504,  505,  506,  507,  508,\n",
       "           509,  510,  511,  512,  513,  514,  515,  516,  517,  518,  519,\n",
       "           520,  521,  522,  523,  524,  525,  526,  527,  528,  529,  550,\n",
       "           551,  552,  553,  554,  555,  556,  557,  558,  559,  570,  571,\n",
       "           572,  573,  574,  575,  576,  577,  578,  579,  590,  591,  592,\n",
       "           593,  594,  595,  596,  597,  598,  599,  620,  621,  622,  623,\n",
       "           624,  625,  626,  627,  628,  629,  640,  641,  642,  643,  644,\n",
       "           645,  646,  647,  648,  649,  670,  671,  672,  673,  674,  675,\n",
       "           676,  677,  678,  679,  790,  791,  792,  793,  794,  795,  796,\n",
       "           797,  798,  799,  860,  861,  862,  863,  864,  865,  866,  867,\n",
       "           868,  869,  890,  891,  892,  893,  894,  895,  896,  897,  898,\n",
       "           899,  910,  911,  912,  913,  914,  915,  916,  917,  918,  919,\n",
       "           940,  941,  942,  943,  944,  945,  946,  947,  948,  949, 1080,\n",
       "          1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1220, 1221,\n",
       "          1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1310, 1311, 1312,\n",
       "          1313, 1314, 1315, 1316, 1317, 1318, 1319, 1380, 1381, 1382, 1383,\n",
       "          1384, 1385, 1386, 1387, 1388, 1389, 1430, 1431, 1432, 1433, 1434,\n",
       "          1435, 1436, 1437, 1438, 1439, 1510, 1511, 1512, 1513, 1514, 1515,\n",
       "          1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526,\n",
       "          1527, 1528, 1529, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597,\n",
       "          1598, 1599, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648,\n",
       "          1649, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679,\n",
       "          1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1810,\n",
       "          1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1830, 1831,\n",
       "          1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1860, 1861, 1862,\n",
       "          1863, 1864, 1865, 1866, 1867, 1868, 1869, 1900, 1901, 1902, 1903,\n",
       "          1904, 1905, 1906, 1907, 1908, 1909, 1940, 1941, 1942, 1943, 1944,\n",
       "          1945, 1946, 1947, 1948, 1949, 1960, 1961, 1962, 1963, 1964, 1965,\n",
       "          1966, 1967, 1968, 1969, 2020, 2021, 2022, 2023, 2024, 2025, 2026,\n",
       "          2027, 2028, 2029, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067,\n",
       "          2068, 2069, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158,\n",
       "          2159, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199,\n",
       "          2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2270,\n",
       "          2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2290, 2291,\n",
       "          2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2420, 2421, 2422,\n",
       "          2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433,\n",
       "          2434, 2435, 2436, 2437, 2438, 2439, 2460, 2461, 2462, 2463, 2464,\n",
       "          2465, 2466, 2467, 2468, 2469]))]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dml_panel_plpr.smpls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7deabe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model rmse\n",
    "\n",
    "# u_hat = dml_panel_plpr._dml_data.y - dml_panel_plpr.predictions['ml_l'].flatten()\n",
    "# v_hat = dml_panel_plpr._dml_data.d - dml_panel_plpr.predictions['ml_m'].flatten()\n",
    "\n",
    "# np.sqrt(np.mean(np.square(u_hat - (dml_panel_plpr.coef[0] * v_hat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11bbc988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLPLPR Object ==================\n",
      "\n",
      "------------------ Data Summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30', 'm_x1', 'm_x2', 'm_x3', 'm_x4', 'm_x5', 'm_x6', 'm_x7', 'm_x8', 'm_x9', 'm_x10', 'm_x11', 'm_x12', 'm_x13', 'm_x14', 'm_x15', 'm_x16', 'm_x17', 'm_x18', 'm_x19', 'm_x20', 'm_x21', 'm_x22', 'm_x23', 'm_x24', 'm_x25', 'm_x26', 'm_x27', 'm_x28', 'm_x29', 'm_x30']\n",
      "Instrument variable(s): None\n",
      "Time variable: time\n",
      "Id variable: id\n",
      "Static panel data: True\n",
      "No. Unique Ids: 250\n",
      "No. Observations: 2500\n",
      "\n",
      "\n",
      "------------------ Score & Algorithm ------------------\n",
      "Score function: partialling out\n",
      "Static panel model approach: cre_general\n",
      "\n",
      "------------------ Machine Learner   ------------------\n",
      "Learner ml_l: LassoCV()\n",
      "Learner ml_m: LassoCV()\n",
      "Out-of-sample Performance:\n",
      "Regression:\n",
      "Learner ml_l RMSE: [[1.72960098]]\n",
      "Learner ml_m RMSE: [[0.95035703]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds per cluster: 5\n",
      "No. folds: 5\n",
      "No. repeated sample splits: 1\n",
      "\n",
      "------------------ Fit Summary       ------------------\n",
      "       coef   std err          t          P>|t|     2.5 %    97.5 %\n",
      "d  0.498106  0.020829  23.913515  2.215861e-126  0.457281  0.538931\n"
     ]
    }
   ],
   "source": [
    "print(dml_panel_plpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d4dbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== DoubleMLPLPR Object ==================\n",
      "\n",
      "------------------ Data summary      ------------------\n",
      "Outcome variable: y\n",
      "Treatment variable(s): ['d']\n",
      "Covariates: ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30', 'm_x1', 'm_x2', 'm_x3', 'm_x4', 'm_x5', 'm_x6', 'm_x7', 'm_x8', 'm_x9', 'm_x10', 'm_x11', 'm_x12', 'm_x13', 'm_x14', 'm_x15', 'm_x16', 'm_x17', 'm_x18', 'm_x19', 'm_x20', 'm_x21', 'm_x22', 'm_x23', 'm_x24', 'm_x25', 'm_x26', 'm_x27', 'm_x28', 'm_x29', 'm_x30']\n",
      "Instrument variable(s): None\n",
      "Time variable: time\n",
      "Id variable: id\n",
      "Static panel data: True\n",
      "No. Unique Ids: 250\n",
      "No. Observations: 2500\n",
      "\n",
      "------------------ Score & algorithm ------------------\n",
      "Score function: partialling out\n",
      "Static panel model approach: cre_general\n",
      "\n",
      "------------------ Machine learner   ------------------\n",
      "Learner ml_l: LassoCV()\n",
      "Learner ml_m: LassoCV()\n",
      "Out-of-sample Performance:\n",
      "Regression:\n",
      "Learner ml_l RMSE: [[1.72960098]]\n",
      "Learner ml_m RMSE: [[0.95035703]]\n",
      "\n",
      "------------------ Resampling        ------------------\n",
      "No. folds per cluster: 5\n",
      "No. folds: 5\n",
      "No. repeated sample splits: 1\n",
      "\n",
      "------------------ Fit summary       ------------------\n",
      "       coef   std err          t          P>|t|     2.5 %    97.5 %\n",
      "d  0.498106  0.020829  23.913515  2.215861e-126  0.457281  0.538931\n"
     ]
    }
   ],
   "source": [
    "print(dml_panel_plpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24f06d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       coef   std err          t          P>|t|    2.5 %    97.5 %\n",
      "d  0.503726  0.022932  21.965879  6.106437e-107  0.45878  0.548672\n"
     ]
    }
   ],
   "source": [
    "# cre normality assumption\n",
    "data = make_static_panel_CP2025(dgp_type='dgp1')\n",
    "cre_data = cre_fct(data)\n",
    "\n",
    "x_cols = [col for col in cre_data.columns if \"x\" in col]\n",
    "\n",
    "obj_dml_data_pdml = DoubleMLPanelData(cre_data,\n",
    "                                      y_col='y',\n",
    "                                      d_cols='d',\n",
    "                                      t_col='time',\n",
    "                                      id_col='id',\n",
    "                                      x_cols=x_cols,\n",
    "                                      static_panel=True)\n",
    "\n",
    "# learner = LassoCV()\n",
    "learner = make_pipeline(StandardScaler(), LassoCV())\n",
    "\n",
    "ml_l = clone(learner)\n",
    "ml_m = clone(learner)\n",
    "\n",
    "obj_dml_plpr = DoubleMLPLPR(obj_dml_data_pdml, ml_l, ml_m, approach='cre_normal')\n",
    "obj_dml_plpr.fit()\n",
    "print(obj_dml_plpr.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61a72563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            coef   std err          t         P>|t|     2.5 %    97.5 %\n",
      "d_diff  0.512959  0.025253  20.313176  9.833638e-92  0.463465  0.562453\n"
     ]
    }
   ],
   "source": [
    "data = make_static_panel_CP2025(dgp_type='dgp1')\n",
    "fd_data = fd_fct(data)\n",
    "\n",
    "obj_dml_data_pdml = DoubleMLPanelData(fd_data,\n",
    "                                 y_col='y_diff',\n",
    "                                 d_cols='d_diff',\n",
    "                                 t_col='time',\n",
    "                                 id_col='id',\n",
    "                                 x_cols=[col for col in fd_data.columns if col.startswith(\"x\")],\n",
    "                                 static_panel=True)\n",
    "\n",
    "learner = LassoCV()\n",
    "ml_l = clone(learner)\n",
    "ml_m = clone(learner)\n",
    "\n",
    "obj_dml_plpr = DoubleMLPLPR(obj_dml_data_pdml, ml_l, ml_m, approach='fd_exact')\n",
    "obj_dml_plpr.fit()\n",
    "print(obj_dml_plpr.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0e322b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m ml_m = clone(learner)\n\u001b[32m     15\u001b[39m obj_dml_plpr = DoubleMLPLPR(obj_dml_data_pdml, ml_l, ml_m, approach=\u001b[33m'\u001b[39m\u001b[33mfd_exact\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mobj_dml_plpr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(obj_dml_plpr.summary)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\doubleml-for-py\\doubleml\\double_ml.py:570\u001b[39m, in \u001b[36mDoubleML.fit\u001b[39m\u001b[34m(self, n_jobs_cv, store_predictions, external_predictions, store_models)\u001b[39m\n\u001b[32m    567\u001b[39m     \u001b[38;5;28mself\u001b[39m._dml_data.set_x_d(\u001b[38;5;28mself\u001b[39m._dml_data.d_cols[i_d])\n\u001b[32m    569\u001b[39m \u001b[38;5;66;03m# predictions have to be stored in loop for sensitivity analysis\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m nuisance_predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_nuisance_and_score_elements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexternal_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_models\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28mself\u001b[39m._solve_score_and_estimate_se()\n\u001b[32m    576\u001b[39m \u001b[38;5;66;03m# sensitivity elements can depend on the estimated parameter\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\doubleml-for-py\\doubleml\\double_ml.py:1088\u001b[39m, in \u001b[36mDoubleML._fit_nuisance_and_score_elements\u001b[39m\u001b[34m(self, n_jobs_cv, store_predictions, external_predictions, store_models)\u001b[39m\n\u001b[32m   1083\u001b[39m ext_prediction_dict = _set_external_predictions(\n\u001b[32m   1084\u001b[39m     external_predictions, learners=\u001b[38;5;28mself\u001b[39m.params_names, treatment=\u001b[38;5;28mself\u001b[39m._dml_data.d_cols[\u001b[38;5;28mself\u001b[39m._i_treat], i_rep=\u001b[38;5;28mself\u001b[39m._i_rep\n\u001b[32m   1085\u001b[39m )\n\u001b[32m   1087\u001b[39m \u001b[38;5;66;03m# ml estimation of nuisance models and computation of score elements\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m score_elements, preds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_nuisance_est\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__smpls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexternal_predictions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mext_prediction_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_models\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore_models\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28mself\u001b[39m._set_score_elements(score_elements, \u001b[38;5;28mself\u001b[39m._i_rep, \u001b[38;5;28mself\u001b[39m._i_treat)\n\u001b[32m   1094\u001b[39m \u001b[38;5;66;03m# calculate nuisance losses and store predictions and targets of the nuisance models\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\doubleml-for-py\\doubleml\\plm\\plpr.py:254\u001b[39m, in \u001b[36mDoubleMLPLPR._nuisance_est\u001b[39m\u001b[34m(self, smpls, n_jobs_cv, external_predictions, return_models)\u001b[39m\n\u001b[32m    252\u001b[39m     l_hat = {\u001b[33m\"\u001b[39m\u001b[33mpreds\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mtargets\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m     l_hat = \u001b[43m_dml_cv_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_learner\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mml_l\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43msmpls\u001b[49m\u001b[43m=\u001b[49m\u001b[43msmpls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs_cv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mest_params\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_params\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mml_l\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predict_method\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mml_l\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_models\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m     _check_finite_predictions(l_hat[\u001b[33m\"\u001b[39m\u001b[33mpreds\u001b[39m\u001b[33m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m._learner[\u001b[33m\"\u001b[39m\u001b[33mml_l\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mml_l\u001b[39m\u001b[33m\"\u001b[39m, smpls)\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# nuisance m\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\doubleml-for-py\\doubleml\\utils\\_estimation.py:76\u001b[39m, in \u001b[36m_dml_cv_predict\u001b[39m\u001b[34m(estimator, x, y, smpls, n_jobs, est_params, method, return_train_preds, return_models)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m smpls_is_partition:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fold_specific_target, \u001b[33m\"\u001b[39m\u001b[33mcombination of fold-specific y and no cross-fitting not implemented yet\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(smpls) == \u001b[32m1\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fold_specific_target  \u001b[38;5;66;03m# fold_specific_target only needed for PLIV.partialXZ\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "data = make_static_panel_CP2025(dgp_type='dgp1')\n",
    "\n",
    "obj_dml_data_pdml = DoubleMLPanelData(data,\n",
    "                                 y_col='y',\n",
    "                                 d_cols='d',\n",
    "                                 t_col='time',\n",
    "                                 id_col='id',\n",
    "                                 x_cols=[col for col in data.columns if col.startswith(\"x\")],\n",
    "                                 static_panel=True)\n",
    "\n",
    "learner = LassoCV()\n",
    "ml_l = clone(learner)\n",
    "ml_m = clone(learner)\n",
    "\n",
    "obj_dml_plpr = DoubleMLPLPR(obj_dml_data_pdml, ml_l, ml_m, approach='fd_exact')\n",
    "obj_dml_plpr.fit()\n",
    "print(obj_dml_plpr.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aeb00efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       coef   std err          t          P>|t|     2.5 %    97.5 %\n",
      "d  0.513121  0.020666  24.828987  4.361657e-136  0.472616  0.553626\n"
     ]
    }
   ],
   "source": [
    "data = make_static_panel_CP2025(dgp_type='dgp1')\n",
    "wd_data = wd_fct(data)\n",
    "\n",
    "obj_dml_data_pdml = DoubleMLPanelData(wd_data,\n",
    "                                      y_col='y',\n",
    "                                      d_cols='d',\n",
    "                                      t_col='time',\n",
    "                                      id_col='id',\n",
    "                                      x_cols=[col for col in wd_data.columns if col.startswith(\"x\")],\n",
    "                                      static_panel=True)\n",
    "\n",
    "learner = LassoCV()\n",
    "ml_l = clone(learner)\n",
    "ml_m = clone(learner)\n",
    "\n",
    "obj_dml_plpr = DoubleMLPLPR(obj_dml_data_pdml, ml_l, ml_m, approach='wg_approx')\n",
    "obj_dml_plpr.fit()\n",
    "print(obj_dml_plpr.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "586d5edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 100.0 %"
     ]
    }
   ],
   "source": [
    "n_reps = 100\n",
    "theta = 0.5\n",
    "\n",
    "learner = make_pipeline(StandardScaler(), LassoCV())\n",
    "\n",
    "res_cre_general = np.full((n_reps, 3), np.nan)\n",
    "res_cre_normal = np.full((n_reps, 3), np.nan)\n",
    "res_fd = np.full((n_reps, 3), np.nan)\n",
    "res_wd = np.full((n_reps, 3), np.nan)\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "for i in range(n_reps):\n",
    "    print(f\"\\rProcessing: {round((i+1)/n_reps*100, 3)} %\", end=\"\")\n",
    "    data = make_static_panel_CP2025(num_n=100, theta=theta, dgp_type='dgp1')\n",
    "\n",
    "    # CRE general Lasso\n",
    "    cre_data = cre_fct(data)\n",
    "    dml_data = DoubleMLPanelData(cre_data, y_col='y', d_cols='d', t_col='time', id_col='id', \n",
    "                                 x_cols=[col for col in cre_data.columns if \"x\" in col],\n",
    "                                 static_panel=True)\n",
    "    dml_plpr = DoubleMLPLPR(dml_data, clone(learner), clone(learner), n_folds=5, \n",
    "                            approach='cre_general')\n",
    "    dml_plpr.fit()\n",
    "    res_cre_general[i, 0] = dml_plpr.coef[0]\n",
    "    res_cre_general[i, 1] = dml_plpr.coef[0] - theta\n",
    "    confint = dml_plpr.confint()\n",
    "    res_cre_general[i, 2] = (confint['2.5 %'].iloc[0] <= theta) & (confint['97.5 %'].iloc[0] >= theta)\n",
    "\n",
    "    # CRE normality\n",
    "    dml_plpr = DoubleMLPLPR(dml_data, clone(learner), clone(learner), n_folds=5, \n",
    "                            approach='cre_normal')\n",
    "    dml_plpr.fit()\n",
    "    res_cre_normal[i, 0] = dml_plpr.coef[0]\n",
    "    res_cre_normal[i, 1] = dml_plpr.coef[0] - theta\n",
    "    confint = dml_plpr.confint()\n",
    "    res_cre_normal[i, 2] = (confint['2.5 %'].iloc[0] <= theta) & (confint['97.5 %'].iloc[0] >= theta)\n",
    "\n",
    "    # FD approach\n",
    "    fd_data = fd_fct(data)\n",
    "    dml_data = DoubleMLPanelData(fd_data, y_col='y_diff', d_cols='d_diff', t_col='time', id_col='id',\n",
    "                                 x_cols=[col for col in fd_data.columns if col.startswith(\"x\")],\n",
    "                                 static_panel=True)\n",
    "    dml_plpr = DoubleMLPLPR(dml_data, clone(learner), clone(learner), n_folds=5, \n",
    "                            approach='fd_exact')\n",
    "    dml_plpr.fit()\n",
    "    res_fd[i, 0] = dml_plpr.coef[0]\n",
    "    res_fd[i, 1] = dml_plpr.coef[0] - theta\n",
    "    confint = dml_plpr.confint()\n",
    "    res_fd[i, 2] = (confint['2.5 %'].iloc[0] <= theta) & (confint['97.5 %'].iloc[0] >= theta)\n",
    "    \n",
    "    # WD approach\n",
    "    wd_data = wd_fct(data)\n",
    "    dml_data = DoubleMLPanelData(wd_data, y_col='y', d_cols='d', t_col='time', id_col='id',\n",
    "                                 x_cols=[col for col in wd_data.columns if \"x\" in col],\n",
    "                                 static_panel=True)\n",
    "    dml_plpr = DoubleMLPLPR(dml_data, clone(learner), clone(learner), n_folds=5, \n",
    "                            approach='wg_approx')\n",
    "    dml_plpr.fit()\n",
    "    res_wd[i, 0] = dml_plpr.coef[0]\n",
    "    res_wd[i, 1] = dml_plpr.coef[0] - theta\n",
    "    confint = dml_plpr.confint()\n",
    "    res_wd[i, 2] = (confint['2.5 %'].iloc[0] <= theta) & (confint['97.5 %'].iloc[0] >= theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33119186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "      <th>Bias</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRE general</th>\n",
       "      <td>0.516684</td>\n",
       "      <td>0.016684</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRE normal</th>\n",
       "      <td>0.541518</td>\n",
       "      <td>0.041518</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FD exact</th>\n",
       "      <td>0.504094</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WG approx</th>\n",
       "      <td>0.502006</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Coef      Bias  Coverage\n",
       "CRE general  0.516684  0.016684      0.92\n",
       "CRE normal   0.541518  0.041518      0.78\n",
       "FD exact     0.504094  0.004094      0.94\n",
       "WG approx    0.502006  0.002006      0.94"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.vstack([res_cre_general.mean(axis=0), res_cre_normal.mean(axis=0), \n",
    "                        res_fd.mean(axis=0), res_wd.mean(axis=0)]), \n",
    "                        columns=['Coef', 'Bias', 'Coverage'], \n",
    "                        index=['CRE general', 'CRE normal', \n",
    "                               'FD exact', 'WG approx'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
